# -*- coding: utf-8 -*-
"""CASE BASED 02 ML - 1301204378.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NY288AKCkQtB2tmk-niPM8UR-FeXDCJ9

# Berlian Muhammad G. A
# 1301204378
# IF-44-10

**CASE BASED 02**
**UNSUPERVISED LEARNING**

---

COUNTRY DATA (NIM GENAP)

Mengelompokkan Negara dengan Menggunakan UNSUPERVISED LEARNING untuk mengkategorikan negara menggunakan faktor sosial-ekonomi dan kesehatan yang menentukan pembangunan negara secara keseluruhan.

**KETERANGAN ATRIBUT**

```
country    : Nama negara

child_mort : Kematian anak di bawah usia 5 tahun per 1000 kelahiran hidup

exports    : Ekspor barang dan jasa per kapita. Diberikan sebagai % dari usia PDB per kapita

health     : Total pengeluaran kesehatan per kapita. Diberikan sebagai % dari usia PDB per kapita

imports    : Impor barang dan jasa per kapita. Diberikan sebagai % dari usia PDB per kapita

income     : Pendapatan bersih per orang

inflation  : Ukuran tingkat pertumbuhan tahunan Total PDB

life_expect: Jumlah rata-rata tahun hidup seorang anak yang baru lahir jika pola kematian saat ini tetap sama

total_fer  : Jumlah anak yang akan dimiliki setiap wanita jika tingkat kesuburan usia saat ini tetap sama

gdpp       : PDB per kapita. Dihitung sebagai Total PDB dibagi dengan total populasi
```
"""

#import library
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

#import pack untuk ignoring warning
from warnings import filterwarnings
filterwarnings('ignore')

#import dataset
#uploading file dataset

from google.colab import files
uploaded = files.upload()

#converting dataframe

dataset = pd.read_csv("Country-data.csv")
dataset.head()

dataset.tail()

dataset.describe().transpose()

dataset.info()

dataset.shape

#mendeteksi missing value

dataset.isnull().sum()

#mengecek duplikasi data

dataset.duplicated().sum()

#INDEXING
#mengkonversi kolom country dari object menjadi index

dataset['country'].nunique()
dataset.set_index('country', inplace=True)
dataset

"""# **VISUALISASI DATASET**"""

# import seaborn
import seaborn as sns

# import matplotlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm

# import plotly untuk grafik
import plotly
import plotly.express as px

"""**PERSEBARAN DATA**"""

#visualisasi

sns.pairplot(data=dataset,diag_kind='kde')
plt.show()

"""**DETEKSI DATA PENCILAN (OUTLIERS)**"""

#boxplot data pencilan

fig, ax = plt.subplots(nrows = 3, ncols = 3, figsize=(20, 10))

for variable, subplot in zip(dataset.columns, ax.flatten()):
      sns.boxplot(dataset[variable], ax = subplot, color='purple')
plt.show()

"""**KORELASI**"""

#korelasi data

corr = dataset.corr()
mask = np.triu(np.ones_like(corr, dtype=np.bool))
f, ax = plt.subplots(figsize=(10, 10))
cmap = sns.light_palette('purple', as_cmap=True)
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=None, center=0, square=True, annot=True, 
            linewidths=.5, cbar_kws={"shrink": .9})
plt.show()

dataset.corr()

"""# **STANDARISASI DATASET**

Scalling data diperlukan untuk algoritma yang didasarkan pada jarak seperti K-means dan Hierarchical clustering.

StandardScaler mengubah data sedemikian rupa sehingga rata-rata menjadi 0 dan varian menjadi 1.
"""

#import untuk preprosesing
from sklearn.preprocessing import StandardScaler

#standarisasi

ss = StandardScaler()

scaled_df = ss.fit_transform(dataset)
X = pd.DataFrame(scaled_df, columns=dataset.columns, index = dataset.index)

X.head()

"""# **Principal Component Analysis**

Principal Component Analysis (PCA) adalah salah satu metode reduksi dimensi pada ML. PCA akan memilih variabel-variabel yang mampu menjelaskan sebagian besar variabilitas data.

Metoda PCA digunakan jika data yang ada memiliki jumlah variabel yang besar dan memiliki korelasi antar variabelnya. Perhitungan dari principal component analysis didasarkan pada perhitungan nilai eigen dan vektor eigen yang menyatakan penyebaran data dari suatu dataset.
"""

from sklearn.decomposition import PCA

pca = PCA()
pcdata = pca.fit_transform(X)

pca_df = pd.DataFrame(pcdata)
pca_df.head()

y = np.cumsum(pca.explained_variance_ratio_)
y

mypca = PCA(n_components=2)
pca5 = mypca.fit_transform(X)
pca5_df = pd.DataFrame(pca5, index=dataset.index)
pca5_df

"""# **ELBOW METHOD**

Elbow method adalah metoda yang sering dipakai untuk menentukan jumlah cluster.

• Semakin banyak cluster, Sum-Square-Error semakin rendah

• Memilih jumlah minimum cluster

**ketika SSE mulai naik level**

• Gunakan Cross Validation dan rata-rata SSE setiap fold
"""

#ELBOW PLOT

from sklearn.cluster import KMeans

elbow = []

for i in range(1,10):
    kmeans = KMeans(n_clusters = i,random_state = 10)
    kmeans.fit(pca5_df)
    elbow.append(kmeans.inertia_)

plt.figure(figsize=(10,6))
plt.plot(range(1,10), elbow, marker="o", color="purple")
plt.title('ELBOW PLOT', fontsize = 20)
plt.xlabel('CLUSTER', fontsize = 15)
plt.ylabel('SSE', fontsize = 15)
plt.grid(True)
plt.show()

"""# **HIERARCHICAL CLUSTERING**

Hierarchical Clustering adalah algoritma yang mengelompokkan objek serupa ke dalam kelompok yang disebut cluster. Titik akhir adalah kumpulan cluster, di mana setiap cluster berbeda satu sama lain, dan objek dalam setiap cluster secara umum mirip satu sama lain.

Dalam metode ini, setiap titik data dianggap sebagai satu cluster dan cluster ini dikelompokkan untuk membentuk cluster yang lebih besar dan akhirnya cluster tunggal dari semua pengamatan dibuat.

**(Bottom-Up)**

**Membangun Model :**
Untuk menemukan jumlah cluster yang optimal dengan Dendrogram dan Metode Skor Silhouette.

Pertama, mencari matriks keterkaitan yang mewakili jarak antara cluster berdasarkan metode keterkaitan yang diberikan. Ada beberapa metode linkage seperti **single, complete, average, centroid, dan ward.**

**Memutuskan metode tautan mana yang terbaik :**
Untuk menentukan metode hubungan terbaik dengan menggunakan **koefisien kofenet.** Koefisien kofenet dengan nilai tertinggi merupakan keterkaitan terbaik.
"""

#import library untuk clustering
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score,silhouette_samples,accuracy_score
from scipy.cluster.hierarchy import  dendrogram, cophenet, linkage
from scipy.spatial.distance import pdist

#mencari keterkaitan data dengan 5 metode

methods = ['single','complete','average','ward','centroid']

for i in methods:
    link = linkage(X, method=i)
    coeff, cophenet_dist = cophenet(link, pdist(X))
    print('Koefisien Cophenet untuk', i, ':', coeff)

"""**DENDOGRAM SINGLE LINKAGE**"""

#dendogram single linkage (keterkaitan single)

plt.title('DENDOGRAM SINGLE', fontsize = 15)
plt.xlabel('INDEX', fontsize = 15)
plt.ylabel('JARAK', fontsize = 15)

link=linkage(dataset, method='single')
dendrogram(link, leaf_rotation=75., truncate_mode='lastp', p=20)

plt.show()

"""**DENDOGRAM COMPLETE LINKAGE**"""

#dendogram complete linkage (keterkaitan complete)

plt.title('DENDOGRAM COMPLETE', fontsize = 15)
plt.xlabel('INDEX', fontsize = 15)
plt.ylabel('JARAK', fontsize = 15)

link=linkage(dataset, method='complete')
dendrogram(link, leaf_rotation=75., truncate_mode='lastp', p=20)

plt.show()

"""**DENDOGRAM AVERAGE LINKAGE**"""

#dendogram average linkage (keterkaitan rata-rata)

plt.title('DENDOGRAM AVERAGE', fontsize = 15)
plt.xlabel('INDEX', fontsize = 15)
plt.ylabel('JARAK', fontsize = 15)

link=linkage(dataset, method='average')
dendrogram(link, leaf_rotation=75., truncate_mode='lastp', p=20)

plt.show()

"""**DENDOGRAM CENTROID LINKAGE**"""

#dendogram centroid linkage (keterkaitan centroid)

plt.title('DENDOGRAM CENTROID', fontsize = 15)
plt.xlabel('INDEX', fontsize = 15)
plt.ylabel('JARAK', fontsize = 15)

link=linkage(X, method='centroid')
dendrogram(link, leaf_rotation=75., truncate_mode='lastp', p=20)

plt.axhline(y=18, c='red', ls='--')
plt.show()

"""**DENDOGRAM WARD LINKAGE**"""

#dendogram ward linkage (keterkaitan ward)

plt.title('DENDOGRAM WARD', fontsize = 15)
plt.xlabel('INDEX', fontsize = 15)
plt.ylabel('JARAK', fontsize = 15)

link=linkage(X, method='ward')
dendrogram(link, leaf_rotation=75., truncate_mode='lastp', p=20)

plt.axhline(y=18, c='red', ls='--')
plt.show()

"""Dari semua dendrogram plotting linkage ward mampu mengelompokkan data dengan jelas. Jadi, saya mempertimbangkan ward linkage sebagai metode linkage terbaik.

**SKOR SILHOUETTE**
"""

#mencari skor silhouette

n_cluster = [2,3,4,5]

for K in n_cluster:
    siluet  = AgglomerativeClustering(n_clusters=K)
    predict = siluet.fit_predict(X)
    s_score = silhouette_score(dataset,predict,random_state=10)
    print("Untuk Cluster {} skor silhouettenya : {}".format(K, s_score) )

"""Dari output di atas untuk 2 cluster skor silhouette terbaik yaitu 0,70.

Jadi, untuk cluster = 2 adalah **cluster terbaik**.
"""

#membangun model dengan k = 2
agglo_clust = AgglomerativeClustering(n_clusters=2, linkage='ward')
agglo_clust.fit(X)

set(agglo_clust.labels_)

country_agglo_df = dataset.copy()
country_agglo_df['clusters'] = agglo_clust.labels_
country_agglo_df

"""# **ANALISIS**"""

country_agglo_df['clusters'].value_counts()

#analisis hierarchial clustering

country_agglo_df.groupby(["clusters"]).mean()

"""**KESIMPULAN**

Cluster 0 = negara berkembang

Cluster 1 = negara maju


**DENGAN HASIL CLUSTERING**

Jumlah negara maju 34

Jumlah negara berkembang 133

# **HASIL ANALISIS**
"""

# List negara berkembang
n_berkembang=country_agglo_df[country_agglo_df['clusters']==0]
n_berkembang.index

# List negara maju
n_maju=country_agglo_df[country_agglo_df['clusters']==1]
n_maju.index

"""**VISUALISASI**"""

from plotly.offline import iplot
import plotly.graph_objects as go


fig_cases = go.Figure(data = go.Choropleth(locations = country_agglo_df.index,
                                     z = country_agglo_df['clusters'],
                                     locationmode = 'country names',
                                     colorscale = [[0, 'teal'],[0.5, 'green'],[1, 'gold']],
                                     colorbar = {'title':'CLUSTER'},
                                     colorbar_title = "CLUSTER"))

fig_cases.update_layout(
                       title_text='GRAFIK GEOGRAFIS UNTUK 167 NEGARA DI DUNIA',
                       geo = dict(showframe = True,showcoastlines = False)
                       )

iplot(fig_cases)

"""Ada 133 negara di Cluster 0 berwarna hijau (ditandai dengan menunjukkan nilai rata-rata menuju negatif untuk semua fitur jika dibandingkan dengan Cluster 1) yang berlokasi hampir di seluruh Amerika Selatan, sebagian Afrika, Eropa, dan Asia.

Ada 34 negara di Cluster 1 berwarna kuning (ditandai dengan menunjukkan nilai-nilai positif seperti pembangunan ekonomi yang baik, harapan hidup yang tinggi, angka kematian anak yang rendah) terletak di Amerika Utara, Australia, Eropa dan beberapa di Asia.


"""

plt.figure(figsize=(5,5))
plt.pie(country_agglo_df.clusters.value_counts(), colors=['teal', 'yellow'], explode=(0.04, 0),
autopct='%1.2f%%', shadow=True, startangle=90, labels=['NEGARA BERKEMBANG','NEGARA MAJU'])

plt.axis('equal')
plt.show()